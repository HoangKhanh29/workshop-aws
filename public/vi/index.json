[{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/1-introduce/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu Xây dựng Hệ thống Streaming Dữ liệu Thời gian Thực với AWS Kinesis, Lambda Functions và S3 Bucket là một cách tiếp cận serverless để trích xuất, biến đổi và tải (ETL) dữ liệu theo thời gian thực. Trong mô hình này, Amazon Kinesis Data Streams sẽ thu thập dữ liệu streaming, AWS Lambda sẽ xử lý và biến đổi dữ liệu đó, và kết quả cuối cùng sẽ được lưu trữ trong Amazon S3 bucket để phân tích thêm hoặc lưu trữ lâu dài.\nViệc sử dụng hệ thống này mang lại nhiều lợi ích so với các phương pháp truyền thống:\nKhông cần quản lý máy chủ: AWS Lambda tự động mở rộng quy mô dựa trên lượng dữ liệu đến từ Kinesis streams, loại bỏ nhu cầu quản lý máy chủ. Xử lý dữ liệu thời gian thực: Dữ liệu được xử lý ngay khi đến Kinesis, cho phép biến đổi và phân tích tức thì. Tiết kiệm chi phí: Bạn chỉ trả tiền cho những gì mình sử dụng với AWS Lambda và S3, giúp giảm chi phí hạ tầng so với máy chủ truyền thống. Tăng cường bảo mật: Dữ liệu được xử lý trong môi trường an toàn, giảm thiểu rủi ro như lộ cổng dịch vụ hoặc phải quản lý khóa SSH. Giám sát toàn diện: AWS CloudWatch tích hợp liền mạch, cung cấp nhật ký và số liệu chi tiết để giám sát toàn bộ quá trình ETL. Dễ dàng truy cập: Dữ liệu đã xử lý được lưu trữ trong Amazon S3, dễ dàng tích hợp với các dịch vụ AWS khác cho việc phân tích hoặc lưu trữ lâu dài. Bằng cách tận dụng Kinesis, Lambda và S3, bạn có thể tạo ra một giải pháp ETL thời gian thực có khả năng mở rộng, tiết kiệm chi phí và an toàn — mà không cần phải quản lý hạ tầng truyền thống phức tạp.\n"},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/","title":"Serverless File System","tags":[],"description":"","content":"Xử lý dữ liệu thời gian thực với Kinesis, Lambda và S3 Tổng quan Workshop này hướng dẫn bạn xây dựng một hệ thống thông báo và quản lý tệp serverless sử dụng các dịch vụ AWS. Có hai cấp độ triển khai:\nOption 1 (Cơ bản): Xử lý sự kiện tải file lên S3, kích hoạt Lambda Function, và gửi thông báo qua SNS đến email. Option 2 (Nâng cao): Hệ thống mở rộng với DynamoDB, SQS, API Gateway, CloudWatch và giao diện web để quản lý tệp đầy đủ tính năng. Khuyến nghị: Bắt đầu với Option 1 để nắm các khái niệm serverless cơ bản, sau đó chuyển sang Option 2 để khám phá các tính năng nâng cao.\nNội dung Content Introduction Preparation Setting-create-s3 Setting-up-kinesis Logging-with-cloudwatch Cleaning-up-resources "},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/2-prerequiste/2.1-create-iam-role/","title":"Tạo IAM","tags":[],"description":"","content":"Trong bước này, chúng ta cần tạo IAM Role, gán quyền S3 Full Access, Kinesis Full Access và CloudWatch Full Access. Gán role data-role cho cả ba Lambda function: Producer, Customer#1 và Customer#2 để đảm bảo khả năng truy cập các dịch vụ cần thiết.\nSau khi hoàn thành bước này, sơ đồ kiến trúc tổng quan sẽ như sau:\nTạo IAM Role Truy cập Create IAM Role Nhấp vào IAM. Nhấp Create Role. Chọn AWS service, sau đó chọn Lambda để xác nhận. Truy cập Add permission Chọn CloudWatchFullAccess. Chọn AmazonS3FullAccess. Chọn AmazonKinesisFullAccess. Truy cập Name, review, and create Đặt tên data-streaming-system-role. Nhấp Create Role. "},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/4-setting-up-kinesis/4.1-create-kinesis-data/","title":"Tạo Kinesis Data","tags":[],"description":"","content":"Tạo Kinesis Data Truy cập Tạo Kinesis\nTìm kiếm Kinesis. Nhấp Create data stream.\nVào Data stream configuration\nTên: jinmeister-data-stream. Chọn Provisioned. Số lượng provisioned shards: 2.\nVào jinmeister-data-stream\nHoàn tất Create Kinesis. Nhấp Configuration. Nhấp Encryption và chọn Edit.\nChọn Enable server-side encryption. Nhấp Save Changes.\n"},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/3-setting-create-s3/3.1-create-s3/","title":"Tạo S3","tags":[],"description":"","content":" Truy cập Create S3. Nhấp S3. Nhấp Create bucket. Đặt tên jinmeister-datasource.\nNhấp Enable. "},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/4-setting-up-kinesis/4.2-update-lambda/","title":"Cập nhật Lambda","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ cập nhật Lambda.\nCập nhật Lambda Vào Lambda Producer Chỉnh sửa đoạn mã sau: const AWS = require(\u0026#39;aws-sdk\u0026#39;); AWS.config.update({ region: \u0026#34;us-east-1\u0026#34; }); const s3 = new AWS.S3(); const kinesis = new AWS.Kinesis(); export const handler = async (event) =\u0026gt; { console.log(JSON.stringify(event)); const bucketName = event.Records[0].s3.bucket.name; const keyName = event.Records[0].s3.object.key; const params = { Bucket: bucketName, Key: keyName }; await s3.getObject(params).promise().then(async (data) =\u0026gt; { const dataString = data.Body.toString(); const payload = { data: dataString }; await sendToKinesis(payload, keyName); }, error =\u0026gt; { console.error(error); }); }; async function sendToKinesis(payload, partitionKey) { const params = { Data: JSON.stringify(payload), PartitionKey: partitionKey, StreamName: \u0026#39;demo-datasrc-stream\u0026#39; }; await kinesis.putRecord(params).promise().then(response =\u0026gt; { console.log(response); }, error =\u0026gt; { console.error(error); }); } 2. Vào Lambda Consumer#1 và Lambda Consumer#2\n- Chỉnh sửa mã của Consumer#1 và Consumer#2\n- Thay cusumer#1 bằng cusumer#2\nexport const handler = async (event) =\u0026gt; { console.log(JSON.stringify(event)); for (const record of event.Records) { const data = JSON.parse(Buffer.from(record.kinesis.data,\u0026#39;base64\u0026#39;)); console.log(\u0026#39;cusumer #1\u0026#39;,data); } }; export const handler = async (event) =\u0026gt; { console.log(JSON.stringify(event)); for (const record of event.Records) { const data = JSON.parse(Buffer.from(record.kinesis.data,\u0026#39;base64\u0026#39;)); console.log(\u0026#39;cusumer #2\u0026#39;,data); } }; Thêm Trigger Vào Lambda Customer#1 và Lambda Customer#2 Nhấn Add trigger Chọn VPC Lattice "},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/2-prerequiste/","title":"Chuẩn bị","tags":[],"description":"","content":"Chuẩn bị Bạn cần chuẩn bị các tài nguyên AWS ban đầu, bao gồm việc tạo một IAM Role với các quyền cần thiết cho Kinesis và Lambda Functions.\nĐể cho phép Lambda Functions quản lý và xử lý dữ liệu từ Kinesis cũng như lưu trữ dữ liệu vào S3, chúng ta cần thiết lập một IAM Role cấp quyền cho các dịch vụ này. Trong bước chuẩn bị này, trước tiên chúng ta sẽ tạo một IAM Role để đảm bảo Lambda có đầy đủ quyền làm việc với Kinesis và S3. Sau đó, chúng ta sẽ tiến hành cấu hình các dịch vụ như Kinesis.\nNội dung Tạo IAM Role Tạo Lambda Functions "},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/3-setting-create-s3/3.2-consumer-lambda-function/","title":"Lambda Function cho Consumer","tags":[],"description":"","content":" Truy cập Create S3.\nVào bucket jinmeister-datasource. Nhấp Properties. Nhấp Event Notifications. Nhấp Create event notification.\nVào Create Event Notification\nName: data-upload / .txt. Chọn All object create events. Chọn Lambda Function. Nhấp choose from your Lambda function. Lambda function: producer.\n"},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/2-prerequiste/2.2-lambda-functions/","title":"Tạo Lambda Functions","tags":[],"description":"","content":"Tạo Lambda Functions Trong bước này, sau khi tạo Role, chúng ta sẽ tạo Lambda producer và chọn data-role để làm execution role.\nHàm này sẽ lắng nghe sự kiện từ S3, đọc dữ liệu từ các object được tải lên S3 và gửi dữ liệu này đến Kinesis stream.\nĐối với Lambda function dành cho consumers: bạn sẽ tạo thêm hai Lambda function cho hai consumer — customer #1 và customer #2 — để xử lý dữ liệu từ Kinesis stream.\nTruy cập Lambda Tìm kiếm Lambda. Nhấp Lambda, sau đó nhấp Create a function để xác nhận. Truy cập Create function Tạo: producer, customer#1, customer#2 / Name: producer, customer#1, customer#2. Chọn Node.js 20.x Chọn Use an existing role Chọn data-streaming-system-role "},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/3-setting-create-s3/","title":"OPTION 1: Hệ thống Cơ bản","tags":[],"description":"","content":"Trong Option 1, chúng ta sẽ xây dựng một hệ thống thông báo file cơ bản sử dụng kiến trúc serverless. Hệ thống này sẽ tự động gửi email thông báo mỗi khi có file mới được upload lên S3 bucket.\nKiến trúc hệ thống:\nS3 Bucket: Lưu trữ file và tạo event khi có file mới Lambda Function: Xử lý event từ S3 và gửi thông báo SNS Topic: Gửi email thông báo đến người dùng Luồng hoạt động:\nUser upload file lên S3 Bucket S3 tạo event và trigger Lambda Function Lambda xử lý event và gửi message đến SNS Topic SNS gửi email thông báo đến subscriber Nội dung 3.1. Tạo S3 Bucket 3.2. Tạo SNS Topic 3.3. Tạo Lambda Function\n"},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/4-setting-up-kinesis/","title":"Hệ thống Kinesis","tags":[],"description":"","content":"Kinesis Stream: Bạn tạo một data stream có tên jinmeister-datasource-stream để xử lý dữ liệu từ Lambda.\nKinesis được cấu hình để tự động mở rộng dựa trên số lượng shard, cân bằng giữa khả năng đọc và ghi.\nTính năng mã hóa phía máy chủ (server-side encryption) được bật để tăng cường bảo mật, đảm bảo dữ liệu trong stream được mã hóa.\nNội dung 4.1. Tạo Kinesis 4.2. Cập nhật Lambda \\\n"},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/5-logging-with-cloudwatch/","title":"Ghi log với CloudWatch","tags":[],"description":"","content":" Tạo file mới Test.txt.\nVào Amazon S3\nClick Objects. Click Upload.\nClick Add files sau đó chọn file test.file vừa tạo.\nQuay lại Lambda Producer\nClick Log streams. Chọn một log stream theo thời gian trùng với thời điểm bạn upload file để kiểm tra.\nQuay lại Lambda Consumer#1 và Consumer#2 Chọn một log stream theo thời gian trùng với thời điểm bạn upload file để kiểm tra.\nMột file mới đã được thêm thành công vào S3 bucket.\n"},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Chúng ta sẽ thực hiện các bước sau để xóa các tài nguyên đã tạo trong bài thực hành này.\nXóa S3 Bucket Vào Amazon S3\nClick Instances. Click tên jinmeister-datasource. Nhập lại tên S3 sau đó xóa. Click Delete bucket.\nXóa Lambda Vào Lambda\nClick Applications. Chọn Producer, Consumer#1 và Consumer#2. Click Actions sau đó nhập Delete.\nXóa IAM role Click Roles. Click role namedata-streaming-system-role sau đó click Delete, nhập lại tên và xóa.\n"},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://hoangkhanh29.github.io/workshop-aws/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]